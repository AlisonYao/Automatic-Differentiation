{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0pTY94sXKav"
   },
   "source": [
    "# best_autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKMYHK9hxdZE"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvEkmNTIbCr0"
   },
   "source": [
    "Our package **best_autodiff** implements the forward and reverse modes of Automatic Differentiation (AD), solving the problem on how to estimate a functionâ€™s derivatives. While symbolic or numerical differentiation might be costly and produces unstable results, AD is both accurate to machine precision and computationally efficient. By breaking down the original function into a sequence of basic operations and applying the chain rule, AD accomplishes to outperform other classic techniques such as symbolic and numerical differentiation. Its relevance stems from the fact that derivatives are a fundamental calculus tool, widely used in a broad range of fields in science and engineering, and placed at the core of machine learning applications. For example, in deep learning, training and testing a neural network involves calculating a large quantity of gradients tens of thousands of times. For efficiency and accuracy, the forward and backpropagation methods for training/testing a neural network can make use of the forward and reverse modes of AD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6678ImlZXm8R"
   },
   "source": [
    "## Background\n",
    "\n",
    "### Introduction\n",
    "*Automatic Differentiation (AD)* is a method for calculating the derivative of a function $f(x)$ specified by a computer program. Any function can be broken down into a sequence of elementary operations, where each operation results in an intermediate value $v_i$ with i being the $i^{th}$ operation. We can represent this with a graph where each intermediate value corresponds to node.  An example of such a graph, called a *computational (forward) graph*, is given below:\n",
    "\n",
    "**Example** <br>\n",
    "Computational forward graph for $f(x) = sin(4x)$\n",
    "![Screen Shot 2022-12-09 at 9.04.14 PM.png](data:image/png;base64,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)\n",
    "\n",
    "We can then repeatedly apply the *chain rule* to each elementary operation to compute derivatives. \n",
    "\n",
    "An example of the chain rule for a simple function is given below:\n",
    "<br>\n",
    "\n",
    "**Example** <br>\n",
    "$\\frac{dy}{dx}f(x) = \\sin(4x)$\n",
    "- $\\frac{dy}{dx}f(x) = \\frac{dy}{du}\\sin(4x) * \\frac{du}{dx}4x$\n",
    "- $\\frac{dy}{dx}f(x) = cos(4x)4$\n",
    "<br>\n",
    "\n",
    "Our package implements the forward and reverse modes of AD. This includes the implementation of dual numbers and the computational graph.\n",
    "\n",
    "### Forward Mode\n",
    "During forward mode, we simultaneously compute the *primal trace* (value) and *tangent trace* (derivatives) of a function. For the primal trace, we evaluate each intermediate value. During the tangent trace we take the intermediate values's derivatives with respect to a specific direction. We can define the *directional gradient* as $D_py_i = \\sum_{j = 1}^{m}\\frac{dy_i}{dx_j}p_j$. This is the projection of the gradient in the direction of the seed vector $p$. Once we choose our direction $p$, we calculate $D_pv_i$ for each intermediate $v_i$ (note: the $y_i$ in the $D_py_i$ definition correspond to our $v_i$).\n",
    "\n",
    "**Example:**\n",
    "AD for $f(x) = sin(4x)$ at $x = \\frac{\\pi}{4}$ <br>\n",
    "\n",
    "First we need to choose a $p$. In this example our input is 1D, therefore, p = 1 is the logical choice for our direction. Thus we get $D_py_i = \\frac{dy_i}{dx_i}$ where $y_i$ are the intermediate variables $v_i$. Next, we compute the *forward primal trace* and the *forward tangent trace* simultaneously.\n",
    "\n",
    "\n",
    "|Primal Trace|Tangent Trace| Numerical Value of $v_i$; $D_pv_i$| \n",
    "|:---|:---|:---|\n",
    "|$v_0 = \\frac{\\pi}{4}$|$D_pv_0 = 1$         |0.78539816339 ; 1  |          \n",
    "|$v_1 = 4v_0$         |$D_pv_1 = 4D_pv_0$   |3.14159265359 ; 4 |          \n",
    "|$v_2 = f(x) = sin(v_1)$|$D_pv_2 = cos(v_1)D_pv_1$|0 ; -4 |                        \n",
    "\n",
    "The value of the tangent trace given in the last row is the derivative that we are looking for: $D_pv_2 = \\frac{df}{dx}f(x)$ where x = $\\frac{\\pi}{4}$. Looking at how we compute the *forward tangent trace*, you can see the use of the chain rule.\n",
    "\n",
    "Next, let's consider the higher dimensional case where our $f(x)$ is a vector function i.e. $f(x)$ maps inputs in the dimension $R^m$ to $R^n$. The gradient of a such a function is the Jacobian. Let's look at an example where m = 2 and n = 2. There are 2 possible directions: $p_1 = [1,0]^T$ and $p_2 = [0,1]^T$. If we take the direction gradient with the first direction $p_1$ we get the first column of the Jacobian and if we use $p_2$ we get the second column of the Jacobian. Therefore we can compute the Jacobian using m passes where each direction vector $p_i$ are set to the $m^{th}$ unit vector along $x_m$ in the $m^{th}$ pass. \n",
    "\n",
    "In summary, forward mode AD works by: \n",
    "1. Breaking down a function into a sequence of elementary operations/functions\n",
    "2. From the inside out, simultaneously compute:\n",
    "    - The forward primal trace: evaluting our intermediate values.\n",
    "    - The forward tangent trace: computing the derivatives of our intermediate values in a specified direction using the chain rule.\n",
    "\n",
    "### Dual Numbers\n",
    "In forward mode, we evaluate our intermediate values $v_j$ and their directional gradients $D_pv_j$ at the same time. We want to carry these two values together as a pair. We can do this using *dual numbers*. A dual number is a number $z = a + bÏµ$ where $a$ corresponds to the \"real part\" and $b$ corresponds to the \"dual part\". $a$ and $b$ are real numbers while $Ïµ$ has the property $Ïµ^2=0$ and is not a real number. We can substitute our function as the real part and the derivative of the function as the dual part. There are two key observations:\n",
    "1. Adding such dual numbers is adding the real parts and adding the derivatives in the dual part\n",
    "2. Multiplying such dual numbers is multiplying the real parts and applying the product rule for the derivatives in the dual part\n",
    "3. The chain rule applies to dual numbers\n",
    "In the forward mode setting, we set the real parts of our dual numbers as the intermediate values $v_j$ and dual parts as $D_pv_j$.\n",
    "\n",
    "### Reverse Mode\n",
    "Unlike forward mode, reverse mode uses a two-pass process:\n",
    "\n",
    "1. In the first pass (forward), we compute the primal trace $v_j$ and compute the partial derivatives $\\frac{dv_j}{dv_i}$ where $v_i$ is the parent node (in the computational graph) of $v_j$.\n",
    "\n",
    "2. In the second pass (reverse), we traverse the computational graph backwards and compute the partial derivative of the $i^{th}$ output $f_i$ with respect to the intermediate values (also called the *adjoint* of the intermediate value). We use this to compute $\\sum_{j = child(i)}\\frac{df}{dv_j}\\frac{dvj}{dvi}$ where the first term in the summation is the adjoint of $v_j$.\n",
    "\n",
    "The properties of dual numbers do not work for reverse mode. Therefore, we can create a computational graph data structure along with function overloading to implement reverse mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NHajrGtXqZ7"
   },
   "source": [
    "## How to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb3Pi6dMt-KK"
   },
   "source": [
    "### PyPI Installation\n",
    "Users can install best_autodiff from [Test Python Package Index](https://test.pypi.org/) (PyPI) following the steps given below:\n",
    "1. Create a virtual environment where best_autodiff will run (recommended) `python3 -m venv /path/to/new/virtual/environment`\n",
    "2. Activate virtual environment `source /path/to/new/virtual/environment/bin/activate`\n",
    "3. `pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple best-autodiff`\n",
    "\n",
    "Note to developers: unit tests are included in the source distribution at <a href=\"https://test-files.pythonhosted.org/packages/94/2d/5f6176f07cba032475fea44a1674993fdc0d7636f71e350b9e88bdd8b94b/best_autodiff-0.0.4.tar.gz\"> test PyPI </a>, however they won't be installed automatically in the site-packages directory via pip, following best practices to avoid pollution for regular users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4UjSH0c__v6"
   },
   "source": [
    "### GitHub Installation\n",
    "Users can also install the package using GitHub by following the steps given below:\n",
    "1. Go to the objective directory where you want to install best_autodiff.\n",
    "\n",
    "2. Clone the repository. Using the command line you can type `git clone https://code.harvard.edu/CS107/team02.git`\n",
    "\n",
    "3. Then position yourself into the project root using `cd team02`\n",
    "\n",
    "4. Create a virtual environment where best_autodiff will run (recommended) `python3 -m venv /path/to/new/virtual/environment`\n",
    "\n",
    "5. Activate virtual environment `source /path/to/new/virtual/environment/bin/activate`\n",
    "\n",
    "6. Install `pip install -r requirements.txt`\n",
    "\n",
    "7. Ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlpoeuG_wLwD"
   },
   "source": [
    "###  Forward Mode Demo\n",
    "Our forward mode can be run on the following cases:\n",
    "1. $R â†’ R$ (scalars, 1 function with 1 input)\n",
    "2. $R â†’ R^n$ (vector, multiple functions with 1 input)\n",
    "3. $R^m â†’ R$ (vector, 1 function with multiple inputs)\n",
    "4. $R^m â†’ R^n$ (vectors, multiple functions/outputs with 1 or multiple inputs)\n",
    "\n",
    "When defining vector functions (functions that take in multiple inputs) there are 2 possible ways to do so:\n",
    "```python\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    first way\n",
    "    \"\"\"\n",
    "    return x[0] + x[1]\n",
    "\n",
    "def f(x, y):\n",
    "    \"\"\"\n",
    "    second way\n",
    "    \"\"\"\n",
    "    return x + y\n",
    "```\n",
    "Our forward (and reverse) mode only supports the first way to define functions with multiple inputs. If the user wants to use a function defined the second way they can wrap their function in the following way:\n",
    "\n",
    "```python\n",
    "def f(x, y):\n",
    "        return x + y\n",
    "\n",
    "def h(v):\n",
    "    \"\"\"\n",
    "    wrapper\n",
    "    \"\"\"\n",
    "    return f(*v)\n",
    "\n",
    "forward = ad.Forward(h, 2, 1)\n",
    "x = np.array([1, 2])\n",
    "value,jacobian = forward(x)\n",
    "```\n",
    "This means scalar case functions (1 function, 1 input) should be implemented as follows:\n",
    "```python\n",
    "#without wrapper\n",
    "def f(x):\n",
    "  return x[0]\n",
    "\n",
    "forward = ad.Forward(f, 1, 1)\n",
    "value,jacobian = forward(1)\n",
    "\n",
    "#with wrapper\n",
    "def f_need_to_wrap(x):\n",
    "  return x\n",
    "\n",
    "def h(v):\n",
    "  return f_need_to_wrap(*v)\n",
    "\n",
    "forward = ad.Forward(h, 1, 1)\n",
    "value,jacobian = forward(1)\n",
    "\n",
    "````\n",
    "Examples of how to use our package's forward mode is shown below.\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# import packages\n",
    "import numpy as np\n",
    "import best_autodiff as ad\n",
    "\n",
    "## Example 1: scalar case (1 function, 1 input)\n",
    "def f(x):\n",
    "    return ad.sin(x[0])\n",
    "#instantiate forward mode object for function f that has 1 input and 1 output(function)\n",
    "forward = ad.Forward(f,1,1)\n",
    "#get value and jacobian of function at x = 0\n",
    "value, jacobian = forward(0)\n",
    "\n",
    "\n",
    "## Example 2: vector case (1 function, muliple inputs)\n",
    "def f(x):\n",
    "    return x[0]*x[1]\n",
    "#instantiate forward mode object for function f with multiple inputs\n",
    "forward = ad.Forward(f,2,1)\n",
    "#get value and jacobian at x = [4,5]\n",
    "value, jacobian = forward(np.array([4,5]))\n",
    "#can also get partial derivatives with seed vectors\n",
    "partial_x0 = forward.get_jacobian(np.array([4,5]), np.array([1,0]))\n",
    "partial_x1 = forward.get_jacobian(np.array([4,5]), np.array([0,1]))\n",
    "          \n",
    "\n",
    "## Example 3: multiple functions (multiple functions, 1 or multiple inputs)\n",
    "def f1(x):\n",
    "    return ad.sin(x[0])\n",
    "def f2(x):\n",
    "    x[0]**2 + x[1]**2\n",
    "#instantiate forward mode object for functions [f1,f2] that have multiple inputs x = [x0,x1]\n",
    "forward = ad.Forward([f1,f2],2,2)\n",
    "#get function value and jacobian at x = [0,4]\n",
    "value, jacobian = forward(np.array([0,4]))\n",
    "#can also get weighted partial derivatives with weighted seed vector\n",
    "#use same seed vector for each function:\n",
    "partials_weighted_same = forward.get_jacobian(np.array([0,4]), np.array([2,1/2]))\n",
    "#use different seed vector for each function\n",
    "partials_weighted_different = forward.get_jacobian(np.array([0,4]), np.array([[2,1/2],[2,0]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oS4dxd5GxdZK"
   },
   "source": [
    "### Reverse Mode Demo\n",
    "\n",
    "Our Reverse mode supports the same cases as Forward mode, where the most complex case involves multiple inputs and multiple functions:\n",
    "\n",
    "1. $R â†’ R$ (scalars, 1 function with 1 input)\n",
    "2. $R â†’ R^n$ (vector, multiple functions with 1 input)\n",
    "3. $R^m â†’ R$ (vector, 1 function with multiple inputs)\n",
    "4. $R^m â†’ R^n$ (vectors, multiple functions/outputs with 1 or multiple inputs)\n",
    "\n",
    "Examples\n",
    "```python\n",
    "import numpy as np\n",
    "from best_autodiff.graph import Graph\n",
    "from best_autodiff.rfunctions import *\n",
    "\n",
    "# R -> R\n",
    "def f(x):\n",
    "    return sin(x[0])**3 + sqrt(cos(x[0]))\n",
    "x = 1\n",
    "ad = Reverse(f, 1, 1)\n",
    "ad.evaluate(x) # 1.3308758237356713\n",
    "ad.get_jacobian(x) # 0.5753328132280636\n",
    "\n",
    "# R -> Rn\n",
    "def f0(x):\n",
    "    return x[0]**3\n",
    "def f1(x):\n",
    "    return x[0]\n",
    "def f2(x):\n",
    "    return logistic(x[0])\n",
    "\n",
    "f = [f0, f1, f2]\n",
    "x = 3\n",
    "ad = Reverse(f, 1, 3) # 1 input, 3 outputs\n",
    "ad.evaluate(x)\n",
    "# array([[27.        ],\n",
    "#        [ 3.        ],\n",
    "#        [ 0.95257413]])\n",
    "ad.get_jacobian(x)\n",
    "# array([[27.        ],\n",
    "#        [ 1.        ],\n",
    "#        [ 0.04517666]])\n",
    "\n",
    "\n",
    "# Rm -> R\n",
    "def f(x):\n",
    "    return (sqrt(x[0])/log(x[1]))*x[0]\n",
    "x = [5, 6]\n",
    "ad = Reverse(f, 2, 1) # 2 inputs, 1 output\n",
    "ad.evaluate(x) # array([6.2398665])\n",
    "ad.get_jacobian(x) # array([[ 1.87195995, -0.58042263]])\n",
    "\n",
    "# Rm -> Rn\n",
    "def f1(x):\n",
    "    return exp(-(sin(x[0])-cos(x[1]))**2)\n",
    "\n",
    "def f2(x):\n",
    "    return sin(-log(x[0])**2+tan(x[2]))\n",
    "f = [f1, f2]\n",
    "x = [1, 1, 1]\n",
    "ad = Reverse(f, 3, 2) # 3 inputs, 2 outputs\n",
    "ad.evaluate(x)\n",
    "# array([[0.53082693],\n",
    "#        [0.59780049]])\n",
    "ad.get_jacobian(x)\n",
    "# array([[-2.89414738,  0.35482731,  0.        ],\n",
    "#        [-0.23044861,  0.        ,  1.23700275]])\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUEZFnHtYAza"
   },
   "source": [
    "## Software Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPAJzNzsb3hL"
   },
   "source": [
    "### Tree-Structured Directory\n",
    "\n",
    "best_autodiff will be structured as follows:\n",
    "\n",
    "```\n",
    "team02\n",
    "â””â”€â”€â”€ README.md\n",
    "â””â”€â”€â”€ LICENSE\n",
    "â””â”€â”€â”€ requirements.txt \n",
    "â””â”€â”€â”€ pyproject.toml\n",
    "â””â”€â”€â”€ setup.cfg\n",
    "â”‚\n",
    "â””â”€â”€â”€best_autodiff\n",
    "â”‚   â””â”€â”€â”€ __init__.py\n",
    "â”‚   â””â”€â”€â”€ forward.py\n",
    "â”‚   â””â”€â”€â”€ dualnumber.py\n",
    "|   â””â”€â”€â”€ functions.py\n",
    "|   â””â”€â”€â”€ reverse.py\n",
    "â”‚   â””â”€â”€â”€ graph.py\n",
    "â”‚   â””â”€â”€â”€ rfunctions.py\n",
    "|\n",
    "â””â”€â”€â”€demo\n",
    "|   â””â”€â”€â”€ demo.ipynb\n",
    "â”‚\n",
    "â””â”€â”€â”€docs\n",
    "|   â””â”€â”€â”€ documentation.ipynb\n",
    "â”‚   â””â”€â”€â”€ milestone1.ipynb\n",
    "|   â””â”€â”€â”€ milestone2_progress.md\n",
    "|   â””â”€â”€â”€ milestone2.ipynb\n",
    "â”‚\n",
    "â””â”€â”€â”€tests\n",
    "    â””â”€â”€â”€ test_forward.py\n",
    "    â””â”€â”€â”€ test_dualnumber.py\n",
    "    â””â”€â”€â”€ test_functions.py\n",
    "    â””â”€â”€â”€ test_reverse.py\n",
    "    â””â”€â”€â”€ test_graph.py\n",
    "    â””â”€â”€â”€ test_runctions.py\n",
    "    â””â”€â”€â”€ run_tests.sh\n",
    "    â””â”€â”€â”€ check_coverage.sh\n",
    "    â””â”€â”€â”€ htmlcov\n",
    "\n",
    "```\n",
    "\n",
    "### Modules\n",
    "\n",
    "Our package plans to implement 6 different modules:\n",
    "1. ```forward.py``` implements the forward mode of AD.\n",
    "2. ```reverse.py``` implements the reverse mode of AD.\n",
    "3. ```dualnumber.py``` implements the dual number data structure to support forward mode. This class has overloaded operations (i.e. addition, subtraction, multiplication, division) \n",
    "4. ```functions.py``` implements elementary functions for the dual number data structure, such as sin, cos, tan, exp, log, etc., and is used in forward mode.\n",
    "5. ```graph.py``` implements the computational graph used in the forward and backward passes of reverse mode. \n",
    "6. ```rfunctions.py``` implements elementary functions for the graph data structure, such as sin, cos, tan, exp, log, etc., and is used in reverse mode.\n",
    "\n",
    "### Test Suite\n",
    "\n",
    "A test directory is available, containing a collection of modules with test cases for each module in the source code. We provide a test suite for the six modules implemented: ```forward```, ```dualnumber```, ```functions```, ```reverse```, ```graph``` and ```rfunctions```. We release test and coverage reports and we use the ```pytest``` package. A client can run our test suite as follows:\n",
    "\n",
    "1. cd into our \"tests\" folder\n",
    "2. command to run the tests: ./run_tests.sh CI \n",
    "3. command to get the test coverage: ./run_tests.sh coverage\n",
    "\n",
    "### Package Distribution\n",
    "\n",
    "Our package will be distributed through PyPI with PEP517."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3HO_dtYEGO"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "### Classes\n",
    "Our package implementes the following classes:\n",
    "Forward mode:\n",
    "1. Forward\n",
    "3. DualNumber\n",
    "\n",
    "Reverse mode:\n",
    "1. Graph\n",
    "2. Reverse\n",
    "\n",
    "Additionally, each mode has a dedicated Functions module to override our implemented functions:\n",
    "1. functions (forward)\n",
    "2. rfunctions (reverse)\n",
    "\n",
    "### Data Structures\n",
    "We use/implement the following major data structures:\n",
    "1. DualNumber: used in the forward mode of AD\n",
    "2. Graph: used to implement the computational graph for reverse mode of AD\n",
    "3. NumPy Arrays: used to represent our inputs and outputs (i.e. the jacobian)\n",
    "\n",
    "### Class Methods, Name Attributes, Implementation Details\n",
    "Our code contains docstrings for all of our methods. Each of them describes briefly what the module does, the classes' attributes and modules, the classes and functions' parameters, main raise errors catched and examples. \n",
    "\n",
    "#### Forward\n",
    "A list of class attributes and methods as well as code is given in the forward mode implementation below:\n",
    "\n",
    "```python\n",
    "class Forward:\n",
    "\t\"\"\" Class used to implement Forward mode of Automatic Differentiation for the following cases:\n",
    "\t1. Scalar function\n",
    "\t2. Vector function\n",
    "\t3. Multiple functions\n",
    "\n",
    "\tAttributes\n",
    "\t----------\n",
    "\n",
    "\tf: function or list of functions\n",
    "\t\tFunction(s) to evaluate\n",
    " \n",
    "\tm: int\n",
    "\t\tNumber of inputs to function\n",
    "\n",
    "\tn: int\n",
    "\t\tNumber of outputs to function\n",
    "\n",
    "\n",
    "\tMethods\n",
    "\t-------\n",
    "\t__init__(self, f, m, n)\n",
    "\t\tInstantiate forward mode object\n",
    "\n",
    "\tevaluate(self, x)\n",
    "\t\tCalculate value of functions evaluated at x\n",
    "\n",
    "\tget_jacobian(self, x)\n",
    "\t\tCalculate Jacobian for function evaluated at x\n",
    "\n",
    "\tExample\n",
    "\t-------\n",
    "\t1. SCALAR CASE \n",
    "\t\t1 input and 1 output\n",
    "\n",
    "\t\tdef f(x):\n",
    "\t\t\treturn x**2\n",
    "\n",
    "\t\tfw = Forward(f, 1, 1)\n",
    "\t\tprint(\"value evaluated at 4:\", fw.evaluate(4))\n",
    "\t\t>> value evaluated at 4: 16\n",
    "\t\tprint(\"Jacobian evaluated at 4:\", fw.get_jacobian(4))\n",
    "\t\t>> Jacobian evaluated at 4: 8\n",
    "\n",
    "\t2. Multiple inputs and 1 output\n",
    "\n",
    "\t\tdef f(x):\n",
    "\t\t\treturn x[0]**2 + sin(x[1])\n",
    "\n",
    "\t\tfw = Forward(f, 2, 1)\n",
    "\t\tprint(\"value evaluated at [5, np.pi/2]:\", fw.evaluate(np.array([5, np.pi/2])))\n",
    "\t\t>> value evaluated at [5, np.pi/2]: 26.0\n",
    "\t\tprint(\"Jacobian evaluated at [5, 0]:\", fw.get_jacobian(np.array([5, 0])))\n",
    "\t\t>> Jacobian evaluated at [5, 0]: [10.0, 1.0]\n",
    "\n",
    "\t3. 1 input and multiple outputs\n",
    "\n",
    "\t\tdef f1(x):\n",
    "\t\t\treturn exp(x**2)\n",
    "\n",
    "\t\tdef f2(x):\n",
    "\t\t\treturn 2*cos(x)\n",
    "\n",
    "\t\tfw = Forward([f1, f2], 1, 2)\n",
    "\t\tprint(\"value evaluated at 1:\", fw.evaluate(1))\n",
    "\t\t>> value evaluated at 1: [2.718281828459045, 1.0806046117362795]\n",
    "\t\tprint(\"Jacobian evaluated at 1:\", fw.get_jacobian(1))\n",
    "\t\t>> Jacobian evaluated at 1: [5.43656365691809, -1.682941969615793]\n",
    "\n",
    "\n",
    "\t4. Multiple inputs and multiple outputs\n",
    "\n",
    "\t\tdef f1(x):\n",
    "\t\t\treturn x[0] + x[1]\n",
    "\n",
    "\t\tdef f2(x):\n",
    "\t\t\treturn x[0] * x[1]\n",
    "\n",
    "\t\tdef f3(x):\n",
    "\t\t\treturn exp(x[0])\n",
    "\n",
    "\t\tfw = Forward([f1, f2, f3], 2, 3)\n",
    "\t\tprint(\"value evaluated at [2, 5]:\", fw.evaluate(np.array([2, 5])))\n",
    "\t\t>> value evaluated at [2, 5]: [7, 10, 7.38905609893065]\n",
    "\t\tprint(\"Jacobian evaluated at [1, 2]:\", fw.get_jacobian(np.array([1, 2])))\n",
    "\t\t>> Jacobian evaluated at [1, 2]: [[1, 1], [2, 1], [2.718281828459045, 0.0]]\n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\t_supported_scalars = (float, int, np.int64, np.float64, np.int32, np.float32)\n",
    "\t_supported_lists = (list, np.ndarray)\n",
    "\n",
    "\tdef __init__(self, f, m, n):\n",
    "\t\t\"\"\" Instantiates forward mode object\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tf: list of functions\n",
    "\t\t\tfunction(s) user wants to evaluate\n",
    "\n",
    "\t\tm: int\n",
    "\t\t\tnumber of inputs to function(s)\n",
    "\n",
    "\t\tn: int\n",
    "\t\t\tnumber of outputs of function\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t\tIf the number of inputs is not an integer or less than 1\n",
    "\t\t\tIf the number of outputs is not an integer or less than 1\n",
    "\t\t\tIf there is 1 output and the function is not callable\n",
    "\t\t\tIf there is more than 1 output and function argument is not a list of callable functions\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(m, int):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(m)} for number of inputs\")\n",
    "\n",
    "\t\tif not isinstance(n, int):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(m)} for number of outputs\")\n",
    "\n",
    "\t\tif m < 1:\n",
    "\t\t\traise TypeError(f\"Number of inputs {m} should be at least 1\")\n",
    "\n",
    "\t\tif n < 1:\n",
    "\t\t\traise TypeError(f\"Number of outputs {n} should be at least 1\")\n",
    "\n",
    "\t\tif (n == 1) and (not callable(f)) and (not isinstance(f, self._supported_lists)):\n",
    "\t\t\traise TypeError(f\"Unsupported function type {type(f)}\")\n",
    "\n",
    "\t\tif n > 1 and not isinstance(f, self._supported_lists):\n",
    "\t\t\traise TypeError(f\"Expected a list of functions\")\n",
    "\n",
    "\t\tif isinstance(f, self._supported_lists):\n",
    "\t\t\tfor function in f:\n",
    "\t\t\t\tif not callable(function):\n",
    "\t\t\t\t\traise TypeError(f\"Functions must be callable\")\n",
    "\n",
    "\t\tif isinstance(f, self._supported_lists) and len(f) != n:\n",
    "\t\t\traise TypeError(f\"Unsupported number of functions: expected {n} but received {len(f)} elements\")\n",
    "\n",
    "\t\tself.f = []\n",
    "\t\tself.m = m\n",
    "\t\tself.n = n\n",
    "\n",
    "\t\tif callable(f):\n",
    "\t\t\tself.f.append(f)\n",
    "\t\telse:\n",
    "\t\t\tfor function in f:\n",
    "\t\t\t\tself.f.append(function)\n",
    "\n",
    "\tdef _get_value_highd(self, x):\n",
    "\t\t\"\"\" Calculates value for function with multiple outputs evaluated at x\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# evaluate each function given in instantiation\n",
    "\t\tvalues = []\n",
    "\t\tif self.m == 1:\n",
    "\t\t\tfor f in self.f:\n",
    "\t\t\t\tvalues.append(f(DualNumber(x)).real)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tfor f in self.f:\n",
    "\t\t\t\tval = self._get_value(f, x)\n",
    "\t\t\t\tvalues.append(self._get_value(f, x).squeeze())\n",
    "\n",
    "\t\treturn np.array(values)\n",
    "\n",
    "\tdef _get_value(self, f, x):\n",
    "\t\t\"\"\" Calculates value for function with 1 output evaluated at x\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# if user inputs a scalar, return a scalar\n",
    "\t\tif self.m == 1 and isinstance(x, self._supported_scalars):\n",
    "\t\t\t\treturn f(DualNumber(x)).real\n",
    "\n",
    "\t\t# otherwise, if user inputs an array, return an array\n",
    "\t\telif self.m == 1:\n",
    "\t\t\treturn np.array([f(DualNumber(x[0])).real])\n",
    "\n",
    "\t\t# convert each input into a Dual Number to calculate function evaluation\n",
    "\t\telse:\n",
    "\t\t\tinputs = []\n",
    "\t\t\tfor z in x:\n",
    "\t\t\t\tinputs.append(DualNumber(z, 1))\n",
    "\t\t\treturn np.array([f(inputs).real])\n",
    "\n",
    "\tdef evaluate(self, x):\n",
    "\t\t\"\"\" Evaluate function at given x\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tx: int, float, np.float64, np.int64, np.int32, np.float32 (for scalars) or np.ndarray (for vectors)\n",
    "\t\t\tValue(s) to evaluate function at\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tvalue: int or float (if function has 1 output) or np.ndarray (if function has more than 1 output)\n",
    "\t\t\tResult of function evaluated at given x\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t\tIf the function has 1 input and x is not of type int, float, np.float64, np.int32 or np.float32\n",
    "\t\t\tIf the function has more than 1 input and x is not of type np.ndarray\n",
    "\t\t\tIf the function has more than 1 input and x is not an array of np.float64, np.int32 or np.float32 elements\n",
    "\t\t\tIf the function has more than 1 input and x is not an array of the same length as \n",
    "\t\t\t\tthe number of inputs defined in the AD instantiation\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif (self.m == 1) and (not isinstance(x, self._supported_scalars)) and (not isinstance(x, np.ndarray)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(x)} for inputs\")\n",
    "\n",
    "\t\tif self.m > 1 and not isinstance(x, np.ndarray):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(x)} for function with {self.m} inputs\")\n",
    "\n",
    "\t\tif isinstance(x, np.ndarray):\n",
    "\t\t\tfor element in x:\n",
    "\t\t\t\tif not isinstance(element, self._supported_scalars):\n",
    "\t\t\t\t\traise TypeError(f\"Unsupported type {type(element)} for element {element} inside inputs\")\n",
    "\n",
    "\t\tif isinstance(x, np.ndarray) and len(x) != self.m:\n",
    "\t\t\traise TypeError(f\"Unsupported number of inputs: expected {self.m} and received {len(x)}\")\n",
    "\n",
    "\t\tif self.n > 1:\n",
    "\t\t\treturn self._get_value_highd(x)\n",
    "\t\telse:\n",
    "\t\t\treturn self._get_value(self.f[0], x)\n",
    "\n",
    "\tdef _get_jacobian_highd(self, x):\n",
    "\t\t\"\"\" Calculates Jacobian for function(s) with multiple outputs evaluated at x\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tjacobian = []\n",
    "\n",
    "\t\t# calculate each row of the Jacobian: one for each of the functions given\n",
    "\t\tfor f in self.f:\n",
    "\t\t\tjacobian.append(self._get_jacobian(f, x))\n",
    "\n",
    "\t\treturn np.array(jacobian)\n",
    "\n",
    "\tdef _get_jacobian(self, f, x):\n",
    "\t\t\"\"\" Calculates Jacobian for function(s) with 1 output evaluated at x\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# if user inputs a scalar, return a scalar\n",
    "\t\tif self.m == 1 and isinstance(x, self._supported_scalars):\n",
    "\t\t\treturn f(DualNumber(x,1)).dual\n",
    "\n",
    "\t\t# otherwise, if user inputs an array, return an array\n",
    "\t\telif self.m == 1:\n",
    "\t\t\treturn np.array([f(DualNumber(x[0])).dual])\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tjacobian = []\n",
    "\t\t\tinputs = []\n",
    "\t\t\tfor z in x:\n",
    "\t\t\t\tinputs.append(DualNumber(z, 1))\n",
    "\n",
    "\t\t\t# calculate the partial derivative with respect to each input\n",
    "\t\t\tfor i, val in enumerate(inputs):\n",
    "\t\t\t\tpartial_values = [DualNumber(z.real, 0) for z in inputs]\n",
    "\t\t\t\tpartial_values[i] = val\n",
    "\t\t\t\tjacobian.append(f(partial_values).dual)\n",
    "\n",
    "\t\t\treturn np.array(jacobian)\n",
    "\n",
    "\tdef get_jacobian(self, x, seed = None):\n",
    "\t\t\"\"\" Calculates Jacobian for function evaluated at x\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tx: int, float, np.float64, np.int64, np.int32, np.float32 (if function has 1 input) or np.ndarray (if function has more than 1 input)\n",
    "\t\t\tValue(s) to evaluate Jacobian at\n",
    "\t\t\n",
    "\t\tseed: np.darray corresponding to the directional seed vector\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tvalue: np.ndarray\n",
    "\t\t\tResult of Jacobian evaluated at given x\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t\tIf the function has 1 input and x is not of type int, float, np.int64, np.float64, np.int32, np.float32\n",
    "\t\t\tIf the function has more than 1 input and x is not of type np.ndarray\n",
    "\t\t\tIf the function has more than 1 input and x is not an array of np.float64, np.int32 or np.float32 elements\n",
    "\t\t\tIf the function has more than 1 input and x is not an array of the same length as \n",
    "\t\t\t\tthe number of inputs defined in the AD instantiation\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif (self.m == 1) and (not isinstance(x, self._supported_scalars)) and (not isinstance(x, np.ndarray)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(x)} for inputs\")\n",
    "\n",
    "\t\tif self.m > 1 and not isinstance(x, np.ndarray):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(x)} for function with {self.m} inputs\")\n",
    "\n",
    "\t\tif seed is not None:\n",
    "\t\t\tif not isinstance(seed, np.ndarray):\n",
    "\t\t\t\traise TypeError(f\"Unsupported type {type(seed)} for seed vector\")\n",
    "\t\t\telif self.m != seed.shape[0]:\n",
    "\t\t\t\traise TypeError(f\"Seed of size {seed.shape} doesn't match number of inputs {self.m}\")\n",
    "\n",
    "\t\tif isinstance(x, np.ndarray):\n",
    "\t\t\tfor element in x:\n",
    "\t\t\t\tif not isinstance(element, self._supported_scalars):\n",
    "\t\t\t\t\traise TypeError(f\"Unsupported type {type(element)} for element {element} inside inputs\")\n",
    "\n",
    "\t\tif isinstance(x, np.ndarray) and len(x) != self.m:\n",
    "\t\t\traise TypeError(f\"Unsupported number of inputs: expected {self.m} and received {len(x)}\")\n",
    "\n",
    "\t\n",
    "\t\tif self.n > 1: #more than one function\n",
    "\t\t\tjacobian = self._get_jacobian_highd(x)\n",
    "\t\telse: # 1 function\n",
    "\t\t\tjacobian = self._get_jacobian(self.f[0], x)\n",
    "\t\t\n",
    "\t\tif seed is not None: #seed specified\n",
    "\t\t\treturn np.dot(jacobian,seed)\n",
    "\t\telse: #return full jacobian\n",
    "\t\t\treturn jacobian\n",
    "\n",
    "\tdef __call__(self, x):\n",
    "        \"\"\"\n",
    "        calls the evaluate and get_jacobian methods from the forward object\n",
    "        \"\"\"\n",
    "\t\treturn (self.evaluate(x), self.get_jacobian(x))\n",
    "```\n",
    "\n",
    "#### Reverse\n",
    "Class to evaluate functions at different points and estimate derivatives using a backward pass.\n",
    "\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "reverse module\n",
    "Implements Reverse class: a class to perform the reverse mode of automatic differentiation\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from best_autodiff.graph import Graph\n",
    "from best_autodiff.rfunctions import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "__all__ = [\"Reverse\"]\n",
    "\n",
    "class Reverse:\n",
    "    \"\"\"\n",
    "    Class used to implement Reverse mode of Automatic Differentiation\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    function_list:\n",
    "        numPy array or list of functions to evaluate\n",
    "\n",
    "    input_list:\n",
    "        numPy array or list for the initialization parameters of the functions' inputs\n",
    "    \n",
    "    m:\n",
    "        scalar (int or float) number of inputs\n",
    "    \n",
    "    n:\n",
    "        scalar (int or float) number of functions (outputs)\n",
    "    \n",
    "    function_dict:\n",
    "        Initialized to None.\n",
    "        Dictionary that will contain the variables and their local derivatives\n",
    "    \n",
    "    jacobian_:\n",
    "        Initialized to array of zeros of size [n,m] once _get_gradients() is called.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __init__(self, function_list, input_list, m, n):\n",
    "        instantiates reverse mode object.\n",
    "        Transforms inputs into Graph class and evaluates function at given points\n",
    "        Runs private method _get_gradients()\n",
    "    \n",
    "    evaluate(self):\n",
    "        Returns the primal trace\n",
    "    \n",
    "    get_jacobian(self):\n",
    "        Returns the adjoint trace\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    R -> R\n",
    "    >>> def f(x):\n",
    "    >>>    return sin(x[0])**3 + sqrt(cos(x[0]))\n",
    "    >>> x = 1\n",
    "    >>> ad = Reverse(f, 1, 1)\n",
    "    >>> ad.evaluate(x)\n",
    "    >>> J = ad.get_jacobian(x)\n",
    "    >>> J\n",
    "    0.5753328132280636\n",
    "\n",
    "    Rm -> R\n",
    "    >>> def f(x):\n",
    "    >>>     return (sqrt(x[0])/log(x[1]))*x[0]\n",
    "    >>> x = [5, 6]\n",
    "    >>> ad = Reverse(f, 2, 1)\n",
    "    >>> ad.evaluate(x)\n",
    "    >>> J = ad.get_jacobian(x)\n",
    "    >>> J\n",
    "    array([[ 1.87195995, -0.58042263]])\n",
    "\n",
    "    R -> Rn\n",
    "    >>> def f0(x):\n",
    "    >>>     return x[0]**3 \n",
    "    >>> def f1(x):\n",
    "    >>>     return x[0]\n",
    "    >>> def f2(x):\n",
    "    >>>     return logistic(x[0])\n",
    "    >>> f = [f0, f1, f2]\n",
    "    >>> x = 3\n",
    "    >>> ad = Reverse(f, 1, 3)\n",
    "    >>> ad.evaluate(x)\n",
    "    >>> J = ad.get_jacobian(x)\n",
    "    >>> J\n",
    "    array([[27.        ],\n",
    "       [ 1.        ],\n",
    "       [ 0.04517666]])\n",
    "    \n",
    "    Rm -> Rn\n",
    "    >>> def f1(x):\n",
    "    >>>     return exp(-(sin(x[0])-cos(x[1]))**2)\n",
    "    >>> def f2(x):\n",
    "    >>>     return sin(-log(x[0])**2+tan(x[2]))\n",
    "    >>> f = [f1, f2]\n",
    "    >>> x = [1, 1, 1]\n",
    "    >>> ad = Reverse(f, 3, 2)\n",
    "    >>> ad.evaluate(x)\n",
    "    >>> J = ad.get_jacobian(x)\n",
    "    >>> J\n",
    "    array([[-0.29722477, -0.46290015,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.04586154]])\n",
    "    \"\"\"\n",
    "    _scalars_types = (int, float, np.int32, np.int64, np.float64)\n",
    "    _array_types = (list, np.ndarray)\n",
    "\n",
    "    def __init__(self, function_list, m, n):\n",
    "        \"\"\"\n",
    "        Instantiates reverse mode object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        function_list:\n",
    "            numPy array or list of functions to evaluate\n",
    "\n",
    "        input_list:\n",
    "            numPy array or list for the initialization parameters of the functions' inputs\n",
    "        \n",
    "        m:\n",
    "            scalar (int or float) number of inputs\n",
    "        \n",
    "        n:\n",
    "            scalar (int or float) number of functions (outputs)\n",
    "        \n",
    "        Raises\n",
    "        -------\n",
    "        TypeError if function_list is not of type np.ndarray or list\n",
    "        TypeError if function_list elements are not callable (i.e functions)\n",
    "        TypeError if input_list is not of type np.ndarray or list\n",
    "        TypeError if input_list elements are not int, float, array or list\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> def f1(x):\n",
    "        >>>     return exp(-(sin(x[0])-cos(x[1]))**2)\n",
    "        >>> def f2(x):\n",
    "        >>>     return sin(-log(x[0])**2+tan(x[2]))\n",
    "        >>> f = [f1, f2]\n",
    "        >>> x = [1, 1, 1]\n",
    "        >>> ad = Reverse(f, 3, 2)\n",
    "        \"\"\"\n",
    "        # Validate function_list content\n",
    "        if isinstance(function_list, self._array_types):\n",
    "            if all([callable(f) for f in function_list]):\n",
    "                self.function_list = np.array(function_list)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported non callable object\")\n",
    "        elif callable(function_list):\n",
    "            self.function_list = np.array([function_list])\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(function_list)}\")\n",
    "\n",
    "        # Save number of inputs\n",
    "        if isinstance(m, self._scalars_types):\n",
    "            self.m = m\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(m)}\")\n",
    "        \n",
    "        # Save number of outputs\n",
    "        if isinstance(n, self._scalars_types):\n",
    "            self.n = n  \n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(n)}\")\n",
    "\n",
    "        # Initial dictionary to store local derivatives\n",
    "        self.function_dict = None\n",
    "\n",
    "\n",
    "    def _get_gradients(self):\n",
    "        \"\"\" \n",
    "        Estimates the local derivatives of `variable` \n",
    "        with respect to child variables.\n",
    "        Each node and path is stored in function_dict\n",
    "        \"\"\"\n",
    "        # Array to store local derivatives (needs to be reset every time)\n",
    "        self.jacobian_ = np.zeros((self.n,self.m))\n",
    "\n",
    "        function_dict = {}\n",
    "\n",
    "        for f_value in self.function_list_:\n",
    "            gradients = dict()\n",
    "            \n",
    "            def compute_gradients(variable, path_value):\n",
    "                for child_variable, local_gradient in variable.local_gradients:\n",
    "                    # Multiply the edges of a path\n",
    "                    value_of_path_to_child = path_value * local_gradient\n",
    "                    # Add together the different paths\n",
    "                    gradients[child_variable] = gradients.get(child_variable, np.array([0]*len(value_of_path_to_child))) + np.array(value_of_path_to_child)\n",
    "                    # recurse through graph\n",
    "                    compute_gradients(child_variable, value_of_path_to_child)\n",
    "                if gradients == {}:\n",
    "                    gradients[variable] = np.array([1])\n",
    "\n",
    "            compute_gradients(f_value, path_value=1)\n",
    "            function_dict[f_value] = gradients\n",
    "        # (path_value=1 is from `variable` differentiated w.r.t. itself)\n",
    "        self.function_dict = function_dict\n",
    "        return self.function_dict\n",
    "    \n",
    "    def evaluate(self, input_list):\n",
    "        \"\"\"\n",
    "        Evaluates function_list at given points = x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_list:\n",
    "            numPy array or list for the initialization parameters of the functions' inputs\n",
    "\n",
    "        Rm -> Rn\n",
    "        >>> def f1(x):\n",
    "        >>>     return exp(-(sin(x[0])-cos(x[1]))**2)\n",
    "        >>> def f2(x):\n",
    "        >>>     return sin(-log(x[0])**2+tan(x[2]))\n",
    "        >>> f = [f1, f2]\n",
    "        >>> x = [1, 1, 1]\n",
    "        >>> ad = Reverse(f, 3, 2)\n",
    "        >>> ad.evaluate(x)\n",
    "        array([[0.91328931],\n",
    "       [0.99991037]])\n",
    "        \"\"\"\n",
    "        # Start assuming vector input\n",
    "        self._scalar_input=False\n",
    "\n",
    "        # Validate input_list content\n",
    "        if isinstance(input_list, self._array_types):\n",
    "            if all([isinstance(i, (self._scalars_types, self._array_types)) for i in input_list]):\n",
    "                input_list = np.array(input_list)\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported type {type(input_list)}\")\n",
    "        elif isinstance(input_list, self._scalars_types):\n",
    "            self._scalar_input=True\n",
    "            input_list = np.array([input_list])\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(input_list)}\")\n",
    "\n",
    "        # Transform evaluation point for each input into Graph class\n",
    "        self.input_list_ = np.array([Graph(ins) for ins in input_list])\n",
    "\n",
    "        # Evaluate function at input\n",
    "        self.function_list_ = [f(self.input_list_) for f in self.function_list]\n",
    "\n",
    "        # Get gradients\n",
    "        self._get_gradients()\n",
    "\n",
    "        # Format evaluated functions from gradients\n",
    "        values = np.array([k.value for k in self.function_dict.keys()])\n",
    "        values = values.flatten()\n",
    "\n",
    "        # Format output for scalar or single element array input type\n",
    "        if values.size == 1:\n",
    "            if self._scalar_input:\n",
    "                values = values.item()\n",
    "            else:\n",
    "                values = np.array([values.item()])\n",
    "\n",
    "        return values\n",
    "    \n",
    "    def get_jacobian(self, input_list):\n",
    "        \"\"\"\n",
    "        Returns Jacobian matrix with total derivatives.\n",
    "        Element [i,j] corresponds to the derivative of function i in functinon_list\n",
    "        with respect to variable j in input_list\n",
    "\n",
    "        Rm -> Rn\n",
    "        >>> def f1(x):\n",
    "        >>>     return exp(-(sin(x[0])-cos(x[1]))**2)\n",
    "        >>> def f2(x):\n",
    "        >>>     return sin(-log(x[0])**2+tan(x[2]))\n",
    "        >>> f=[f1, f2]\n",
    "        >>> x = [1, 1, 1]\n",
    "        >>> ad = Reverse(f, 3, 2)\n",
    "        >>> ad.evaluate(x)\n",
    "        >>> ad.get_jacobian(x)\n",
    "        array([[-0.29722477, -0.46290015,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.04586154]])\n",
    "        \"\"\"\n",
    "        self.evaluate(input_list)\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                try:\n",
    "                    self.jacobian_[i][j] = self.function_dict[self.function_list_[i]][self.input_list_[j]]\n",
    "                except:\n",
    "                    self.jacobian_[i][j] = np.array([0])\n",
    "\n",
    "        # Format output for scalar or single element array input type\n",
    "        if self.jacobian_.size == 1:\n",
    "            if self._scalar_input:\n",
    "                self.jacobian_ = self.jacobian_.item()\n",
    "            else:\n",
    "                self.jacobian_ = np.array([self.jacobian_.item()])\n",
    "\n",
    "        return self.jacobian_\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Return function evaluated at x and its respective jacobian matrix\n",
    "        \"\"\"\n",
    "        return (self.evaluate(x), self.get_jacobian(x))\n",
    "\n",
    "\n",
    "# References\n",
    "# https://sidsite.com/posts/autodiff/\n",
    "\n",
    "```\n",
    "\n",
    "#### DualNumber\n",
    "Our DualNumber Class implements Dual Numbers and the overloading of elementary operations so that they work with Dual Numbers. A description of the class methods and attributes as well as the code is given below.\n",
    "\n",
    "\n",
    "```python\n",
    "class DualNumber:\n",
    "\t\"\"\" A class used to represent Dual Numbers \n",
    "\n",
    "\tAttributes\n",
    "\t---------\n",
    "\treal: int, float, np.int32, np.int64 or np.float64\n",
    "\t    the real part of the dual number \n",
    "\n",
    "\tdual: int, float, np.int32, np.int64 or np.float64\n",
    "\t    the dual part of the dual number\n",
    "\n",
    "\tMethods\n",
    "\t-------\n",
    "\t__add__(other)\n",
    "\t    Overloads + operator to support dual number addition with other dual numbers, floats and ints\n",
    "\n",
    "\t__radd__(other)\n",
    "\t    Overloads reflected + operator to support addition of dual numbers\n",
    "\n",
    "\t__mul__(other)\n",
    "\t    Overloads * operator to support dual number multiplication with other dual numbers, floats and ints\n",
    "\n",
    "\t__rmul__(other)\n",
    "\t    Overloads reflected * operator to support multiplication of dual numbers\n",
    "\n",
    "\t__sub__(other)\n",
    "\t    Overloads - operator to support dual number subtraction with other dual numbers, floats and ints\n",
    "\n",
    "\t__rsub__(other)\n",
    "\t    Overloads reflected - operator to support subtraction of dual numbers\n",
    "\n",
    "\t__truediv__(other)\n",
    "\t\tOverloads / operator to support dual number division with other dual numbers, floats and ints\n",
    "\n",
    "\t__rtruediv__(other)\n",
    "\t    Overloads reflected / operator to support dual number division\n",
    "\n",
    "\t__neg__()\n",
    "\t    Overloads - operator to support dual number negation\n",
    "\n",
    "\t__pow__(other)\n",
    "\t    Overloads ** operator to support exponentiation of dual numbers\n",
    "\t\n",
    "\t__rpow__(other)\n",
    "\t    Overloads reflexive ** operator to support reflexive exponentiation of dual numbers\n",
    "\n",
    "\t__rpow__()\n",
    "\t    Overloads reverse ** operator to support exponentiation to the power of dual numbers\n",
    "\n",
    "\t__eq__(z)\n",
    "\t\tOverloads == operator to support checking equality for dual numbers\n",
    "\n",
    "\t__ne__(z)\n",
    "\t\tOverloads != operator to support checking for dual number inequality\n",
    "\n",
    "\t__str__()\n",
    "\t\tReturns string representation of dual numbers\n",
    "\n",
    "\t__repr__()\n",
    "\t\tReturns object representation of dual numbers in string format\n",
    "\t\"\"\"\n",
    "\n",
    "\t_scalars_types = (int, float, np.int32, np.int64, np.float64)\n",
    "\n",
    "\tdef __init__(self, real, dual=1.0):\n",
    "\t\t\"\"\" Initializes instance of class Dual Number\n",
    "\n",
    "\t\tParameters\n",
    "\t\t---------\n",
    "\t\treal: int, float, np.int32, np.int64 or np.float64\n",
    "\t\t    Real part of dual number \n",
    "\n",
    "\t\tdual: int, float, np.int32, np.int64 or np.float64, optional\n",
    "\t\t    Dual part of dual number. If not given, the default is 1.0\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If real or dual arguments are not int, float, np.int32, np.int64 or np.float64\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(real, self._scalars_types):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(real)}\")\n",
    "\t\telif not isinstance(dual, self._scalars_types):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(dual)}\")\n",
    "\n",
    "\t\tself.real = real\n",
    "\t\tself.dual = dual \n",
    "\n",
    "\tdef __add__(self, other):\n",
    "\t\t\"\"\" Overloads + operator to support dual number addition with other dual numbers, floats and ints\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to add to dual number\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the addition\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\tif isinstance(other, self._scalars_types):\n",
    "\t\t\treturn DualNumber(other + self.real, self.dual)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(other.real + self.real, other.dual + self.dual)\n",
    "\n",
    "\tdef __radd__(self, other):\n",
    "\t\t\"\"\" Overloads reflected + operator to support addition of dual numbers\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to add to dual number\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the reflected addition\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\treturn self.__add__(other)\n",
    "\n",
    "\tdef __mul__(self, other):\n",
    "\t\t\"\"\" Overloads * operator to support dual number multiplication with other dual numbers, floats and ints\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to multiply to dual number\n",
    "\t\t\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the multiplication\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\tif isinstance(other, self._scalars_types):\n",
    "\t\t\treturn DualNumber(other*self.real, other*self.dual)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(other.real*self.real, (other.dual*self.real) + (other.real*self.dual))\n",
    "\n",
    "\tdef __rmul__(self, other):\n",
    "\t\t\"\"\" Overloads reflected * operator to support multiplication of dual numbers\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to multiply to dual number\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the reflected multiplication\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\n",
    "\t\treturn self.__mul__(other)\n",
    "\n",
    "\tdef __sub__(self, other):\n",
    "\t\t\"\"\" Overloads - operator to support dual number subtraction with other dual numbers, floats and ints\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to subtract from dual number\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the subtraction\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\tif isinstance(other, self._scalars_types):\n",
    "\t\t\treturn DualNumber(self.real - other.real, self.dual)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(self.real - other.real, self.dual - other.dual)\n",
    "\n",
    "\tdef __rsub__(self, other):\n",
    "\t\t\"\"\" Overloads reflected - operator to support subtraction of dual numbers\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64\n",
    "\t\t    Number to do substraction with\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the reflected subtraction\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, self._scalars_types):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(other - self.real, -self.dual)\n",
    "\n",
    "\tdef __truediv__(self, other):\n",
    "\t\t\"\"\" Overloads / operator to support dual number division with other dual numbers, floats and ints\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to divide from dual number\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the divison\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\n",
    "\t\tZeroDivisionError\n",
    "\t\t\tIf other is 0 or if the real part of other is 0\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\tif isinstance(other, DualNumber) and other.real == 0:\n",
    "\t\t\traise ZeroDivisionError(f\"Attempted division by zero\")\n",
    "\n",
    "\t\tif not isinstance(other, DualNumber) and other == 0:\n",
    "\t\t\traise ZeroDivisionError(f\"Attempted division by zero\")\n",
    "\n",
    "\t\tif isinstance(other, self._scalars_types):\n",
    "\t\t\treturn DualNumber(self.real / other, self.dual / other)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(self.real / other.real, \n",
    "\t\t\t\t((self.dual * other.real) - (self.real * other.dual)) / (other.real * other.real))\n",
    "\n",
    "\tdef __rtruediv__(self, other):\n",
    "\t\t\"\"\" Overloads reflected / operator to support dual number division\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Number to do division with\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the reflected divison\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\n",
    "\t\tZeroDivisionError\n",
    "\t\t\tIf the real part self is 0\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, self._scalars_types):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(other / self.real, -(other * self.dual) / (self.real * self.real))\n",
    "\n",
    "\tdef __neg__(self):\n",
    "\t\t\"\"\" Overloads - operator to support dual number negation\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of negation\n",
    "\t\t\"\"\"\n",
    "\t\treturn DualNumber(-self.real, -self.dual)\n",
    "\n",
    "\tdef __pow__(self, other):\n",
    "\t\t\"\"\" Overloads ** operator to support exponentiation of dual numbers\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t    Power to exponentiate dual number\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the exponentiation\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64 or DualNumber\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other,  (*self._scalars_types, DualNumber)):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\tif isinstance(other, DualNumber):\n",
    "\t\t\treturn DualNumber(self.real ** other.real,\n",
    "\t\t\t\tself.real ** other.real * ((other.dual * np.log(self.real)) + (self.dual * other.real / self.real)))\n",
    "\n",
    "\t\telse:\n",
    "\t\t\treturn DualNumber(self.real**other, other * self.real**(other-1) * self.dual)\n",
    "\n",
    "\tdef __rpow__(self, other):\n",
    "\t\t\"\"\" Overloads reverse ** operator to support exponentiation to the power of dual numbers\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64 or np.float64\n",
    "\t\t    Number to exponentiate\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the reflected exponentiation\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64 or np.float64\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif not isinstance(other, self._scalars_types):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\treturn DualNumber(other, 0).__pow__(self)\n",
    "\n",
    "\tdef __eq__(self, other):\n",
    "\t\t\"\"\" Overloads == operator to support checking for dual number equality\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: DualNumber\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tDualNumber\n",
    "\t\t\tResult of the equality check\n",
    "\n",
    "\t\tRaises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t\tIf other is not a DualNumber\n",
    "\t\t\"\"\"\n",
    "\t\tif not isinstance(other, DualNumber):\n",
    "\t\t\traise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "\t\tif self.real != other.real:\n",
    "\t\t\treturn False \n",
    "\t\tif self.dual != other.dual:\n",
    "\t\t\treturn False \n",
    "\t\treturn True\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn f\"Dual Number {self.real} + {self.dual}E\"\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn f\"DualNumber({self.real}, {self.dual})\"\n",
    "```\n",
    "\n",
    "#### Graph\n",
    "Graph is the class we implemented to handle reverse mode. It constructs the computational graph and allows us to pair evaluated values and their corresponding local derivatives.\n",
    "\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "graph module\n",
    "Implements Graph: a class to represent computational graph for reverse mode\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"\n",
    "    A class used to represent computational graph\n",
    "\n",
    "\tAttributes\n",
    "\t---------\n",
    "\tvalue: int, float, np.int32, np.int64, np.float64, list or np.ndarray\n",
    "\n",
    "\tMethods\n",
    "\t-------\n",
    "\t__add__(other)\n",
    "\t    Overloads + operator to support Graph instances addition with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__radd__(other)\n",
    "\t    Overloads reflected + operator to support Graph instances addition with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__mul__(other)\n",
    "\t    Overloads * operator to support Graph instances multiplication with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__rmul__(other)\n",
    "\t    Overloads reflected * operator to support Graph instances multiplication with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__sub__(other)\n",
    "\t    Overloads - operator to support Graph instances subtraction with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__rsub__(other)\n",
    "\t    Overloads reflected - operator to support Graph instances subtraction with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__truediv__(other)\n",
    "\t\tOverloads / operator to support Graph instances division with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__rtruediv__(other)\n",
    "\t    Overloads reflected / operator to support Graph instances division with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t__pow__(other)\n",
    "\t    Overloads ** operator to support exponentiation of graph instances\n",
    "\t\n",
    "\t__rpow__(other)\n",
    "\t    Overloads reverse ** operator to support reflexive exponentiation of graph instances\n",
    "    \n",
    "    __neg__()\n",
    "\t    Overloads negation operator to support graph instance negation\n",
    "\n",
    "    __lt__():\n",
    "        Overloads < operator to support checking less than for Graph instances\n",
    "    \n",
    "    __gt__():\n",
    "        Overloads > operator to support checking greater than for Graph instances\n",
    "    \n",
    "    __le__():\n",
    "        Overloads <= operator to support checking less or equal than for Graph instances\n",
    "    \n",
    "    __ge__():\n",
    "        Overloads >= operator to support checking greater or equal than for Graph instances\n",
    "\n",
    "\t__eq__():\n",
    "\t\tOverloads == operator to support checking Graph instances equality\n",
    "    \n",
    "    __hash__():\n",
    "        Complements __eq__() function to ensure Graph instances are hashable\n",
    "    \n",
    "    __ne__():\n",
    "        Overloads != operator to support checking Graph instances inequality\n",
    "\n",
    "\t__str__()\n",
    "\t\tReturns string representation of graph\n",
    "\n",
    "\t__repr__()\n",
    "\t\tReturns object representation of graph in string format\n",
    "    \"\"\"\n",
    "    _scalars_types = (int, float, np.int32, np.int64, np.float64)\n",
    "    _array_types = (list, np.ndarray)\n",
    "\n",
    "    def __init__(self, value, local_gradients=()):\n",
    "        \"\"\"\n",
    "        Instantiates graph instance\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        value: int, float, np.int32, np.int64, np.float64, list, or np.ndarray to evaluate\n",
    "\n",
    "        local_gradients: tuple of local gradients. If not given, the default is ()\n",
    "        \n",
    "        Raises\n",
    "        -------\n",
    "        TypeError \n",
    "            If value is not int, float, np.int32, np.int64, np.float64, list, or np.ndarray\n",
    "        \"\"\"\n",
    "        if isinstance(value, self._scalars_types):\n",
    "            self.value = np.array([value])\n",
    "        elif isinstance(value, self._array_types):\n",
    "            for item in value:\n",
    "                if not isinstance(item, self._scalars_types):\n",
    "                    raise TypeError(f\"Unsupported type {type(item)} in list/numpy ndarray\")\n",
    "            self.value = np.array(value)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(value)}\")\n",
    "        self.local_gradients = local_gradients\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\" \n",
    "        Overloads + operator to support Graph instances addition with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64,list, np.ndarray, or Graph\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of supported types\n",
    "\t\t\"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        \n",
    "        value = self.value + other.value\n",
    "        local_gradients = ((self, np.array([1]*len(self.value))), (other, np.array([1]*len(other.value))))\n",
    "        \n",
    "        return Graph(value, local_gradients)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        \"\"\" \n",
    "        Overloads reflected + operator to support Graph instances addition with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64,list, np.ndarray, or Graph\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of supported types\n",
    "\t\t\"\"\"\n",
    "        if not isinstance(other, (*self._scalars_types, *self._array_types, Graph)):\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        \n",
    "        return self.__add__(other)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads - operator to support Graph instances subtraction with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph to subtract from Graph instance\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        value = self.value - other.value\n",
    "        local_gradients = ((self, np.array([1]*len(value))), (other, np.array([-1]*len(value))))\n",
    "        return Graph(value, local_gradients)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads reflected - operator to support Graph instances subtraction with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph to be subtracted from\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        value = other.value - self.value\n",
    "        local_gradients = ((self, np.array([-1]*len(value))), (other, np.array([1]*len(value))))\n",
    "        return Graph(value, local_gradients)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\" \n",
    "        Overloads * operator to support Graph instances multiplication with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64,list, np.ndarray, or Graph\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of supported types\n",
    "\t\t\"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        value = self.value * other.value\n",
    "        local_gradients = (\n",
    "            (self, other.value),\n",
    "            (other, self.value)\n",
    "            )\n",
    "        return Graph(value, local_gradients)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        \"\"\" \n",
    "        Overloads reflected * operator to support Graph instances multiplication with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64,list, np.ndarray, or Graph\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of supported types\n",
    "\t\t\"\"\"\n",
    "        if not isinstance(other, (*self._scalars_types, *self._array_types, Graph)):\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        \n",
    "        return self.__mul__(other)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads / operator to support Graph instances division with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph to divide from Graph instance\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        if 0 in other.value:\n",
    "            raise ZeroDivisionError\n",
    "        value = self.value / other.value\n",
    "        local_gradients = (\n",
    "            (self, 1 / other.value), \n",
    "            (other, -self.value/ other.value**2)\n",
    "        )\n",
    "        return Graph(value, local_gradients)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads reflected / operator to support Graph instances division with other Graph instances, ints, floats, lists and numpy arrays\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph to divide from Graph instance\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        if 0 in self.value:\n",
    "            raise ZeroDivisionError\n",
    "        value = other.value / self.value\n",
    "        local_gradients = (\n",
    "            (other, 1 / other.value), \n",
    "            (self, -1 / self.value**2)\n",
    "        )\n",
    "        return Graph(value, local_gradients)\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        \"\"\" \n",
    "        Overloads ** operator to support exponentiation of graph instances\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64,list, np.ndarray, or Graph\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of supported types\n",
    "\t\t\"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "\n",
    "        value = self.value ** other.value\n",
    "        local_gradients = (\n",
    "            (self, other.value * self.value ** (other.value - 1)),\n",
    "            (other, self.value ** other.value * np.log(self.value))\n",
    "        )\n",
    "        return Graph(value, local_gradients)\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        \"\"\" \n",
    "        Overloads reverse ** operator to support reflexive exponentiation of graph instances\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64,list, np.ndarray, or Graph\n",
    "\n",
    "\t\tRaises\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of supported types\n",
    "\t\t\"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    " \n",
    "        return other.__pow__(self)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"\n",
    "        Overloads negation operator to support graph instance negation\n",
    "        \"\"\"\n",
    "        value = -self.value\n",
    "        local_gradients = (\n",
    "            (self, np.array([-1]*len(self.value))),\n",
    "            )\n",
    "        return Graph(value, local_gradients)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads < operator to support checking less than for Graph instances\n",
    "\n",
    "        Parameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "\n",
    "        Raises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        return np.less(self.value, other.value)\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads > operator to support checking greater than for Graph instances\n",
    "\n",
    "        Parameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "\n",
    "        Raises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        return np.greater(self.value, other.value)\n",
    "\n",
    "    def __le__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads <= operator to support checking less or equal than for Graph instances\n",
    "\n",
    "        Parameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "\n",
    "        Raises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        return np.less_equal(self.value, other.value) \n",
    "\n",
    "    def __ge__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads >= operator to support checking greater or equal than for Graph instances\n",
    "\n",
    "        Parameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "\n",
    "        Raises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        return np.greater_equal(self.value, other.value) \n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads == operator to support checking Graph instances equality\n",
    "\n",
    "        Parameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "\n",
    "        Raises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        return np.equal(self.value, other.value)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Complements __eq__() function to ensure Graph instances are hashable\n",
    "        \"\"\"\n",
    "        return id(self)\n",
    "        # Ref: https://stackoverflow.com/questions/1608842/types-that-define-eq-are-unhashable\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        \"\"\"\n",
    "        Overloads != operator to support checking Graph instances inequality\n",
    "\n",
    "        Parameters\n",
    "\t\t----------\n",
    "\t\tother: int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "\n",
    "        Raises:\n",
    "\t\t------\n",
    "\t\tTypeError\n",
    "\t\t    If other is not of type int, float, np.int32, np.int64, np.float64, list, np.ndarray or Graph\n",
    "        AssertionError\n",
    "            If other is a list, numpy array, or a Graph instance, but the length doesn't match with self\n",
    "        \"\"\"\n",
    "        if isinstance(other, self._scalars_types):\n",
    "            other = Graph([other]*len(self.value))\n",
    "        elif isinstance(other, self._array_types):\n",
    "            assert len(self.value) == len(other), \"Input dimension mismatch\"\n",
    "            other = Graph(np.array(other))\n",
    "        elif isinstance(other, Graph):\n",
    "            assert len(self.value) == len(other.value), \"Input dimension mismatch\"\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type {type(other)}\")\n",
    "        return np.not_equal(self.value, other.value)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Returns string representation of graph\n",
    "        \"\"\"\n",
    "        return f\"Graph({self.value})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns object representation of graph in string format\n",
    "        \"\"\"\n",
    "        return f\"Graph({self.value})\"\n",
    "        \n",
    "\n",
    "# References\n",
    "# https://sidsite.com/posts/autodiff/\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Functions Module\n",
    "The functions and rfunctions modules overload elementary functions that are necessary to use with DualNumbers or the Graph class, depending on the mode.\n",
    "\n",
    "The module is given below:\n",
    "```python\n",
    "\"\"\"\n",
    "functions module\n",
    "Implements mathematical functions for the best_autodiff package\n",
    "Functions are intended to work with dual numbers\n",
    "\n",
    "sqrt(z)\n",
    "\tImplements squared root of a DualNumber\n",
    "\n",
    "log(z, base)\n",
    "\tImplements log function of a DualNumber using any base\n",
    "\n",
    "root(z, n)\n",
    "\tImplements function to take the nth root of a DualNumber\n",
    "\n",
    "exp(z)\n",
    "\tImplements exponential function exp to the power of a DualNumber\n",
    "\n",
    "sin(z)\n",
    "\tImplements sine of a DualNumber\n",
    "\n",
    "cos(z)\n",
    "\tImplements cosine of a DualNumber\n",
    "\n",
    "tan(z)\n",
    "\tImplements tangent of a DualNumber\n",
    "\n",
    "arcsin(z)\n",
    "\tImplements arcsine of a DualNumber\n",
    "\n",
    "arccos(z)\n",
    "\tImplements arccosine of a DualNumber\n",
    "\n",
    "arctan(z)\n",
    "\tImplements arctangend of a DualNumber\n",
    "\n",
    "sinh(z)\n",
    "\tImplements hyperbolic sine of a DualNumber\n",
    "\n",
    "cosh(z)\n",
    "\tImplements hyperbolic cosine of a DualNumber\n",
    "\n",
    "tanh(z)\n",
    "\tImplements hyperbolic tangent of a DualNumber\n",
    "\n",
    "logistic(z)\n",
    "\tImplements the sigmoid logistic function of a DualNumber\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from best_autodiff.dualnumber import DualNumber\n",
    "# from dualnumber import DualNumber\n",
    "\n",
    "\n",
    "__all__ = [\"sqrt\", \"log\", \"root\", \"exp\", \"sin\", \"cos\", \"tan\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"logistic\"]\n",
    "\n",
    "_scalars_types = (int, float, np.int32, np.int64, np.float64)\n",
    "\n",
    "def sqrt(z):\n",
    "\t\"\"\" Implements squared root of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of square root\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\tif z.real < 0:\n",
    "\t\traise ValueError(f\"Domain out of range\")\n",
    "\n",
    "\treturn DualNumber(np.sqrt(z.real), (1 / 2) * (1 / np.sqrt(z.real)) * z.dual)\n",
    "\n",
    "\n",
    "def log(z, base):\n",
    "\t\"\"\" Implements log function of a DualNumber using any base\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\tbase: int, float, np.int32, np.int64 or np.float64\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of log\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not DualNumber\n",
    "\t\tIf base is not int, float, np.int32, np.int64 or np.float64\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\tif not isinstance(base, (int, float, np.int32, np.int64, np.float64)):\n",
    "\t\traise TypeError(f\"Unsupported type {type(base)}\")\n",
    "\n",
    "\treturn DualNumber(np.log(z.real) / np.log(base),\n",
    "\t\tz.dual / (np.log(base) * z.real))\n",
    "\n",
    "def root(z, n):\n",
    "\t\"\"\" Implements function to take the nth root of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\tn: int, float, np.int32, np.int64 or np.float64\n",
    "\t\tnth root of a dual number\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of root\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not DualNumber\n",
    "\t\tIf n is not int, float, np.int32, np.int64 or np.float64\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\tif not isinstance(n, (int, float, np.int32, np.int64, np.float64)):\n",
    "\t\traise TypeError(f\"Unsupported type {type(n)}\")\n",
    "\n",
    "\tif z.real < 0:\n",
    "\t\traise ValueError(f\"Domain out of range\")\n",
    "\n",
    "\treturn DualNumber(np.power(z.real, 1/n),\n",
    "\t\t(np.power(z.real, 1/n) * z.dual) / (n * z.real))\n",
    "\n",
    "def exp(z):\n",
    "\t\"\"\" Implements exponential function exp to the power of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of exp\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.exp(z.real), np.exp(z.real) * z.dual)\n",
    "\n",
    "def sin(z):\n",
    "\t\"\"\" Implements sine of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of sin\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.sin(z.real), np.cos(z.real) * z.dual)\n",
    "\n",
    "def cos(z):\n",
    "\t\"\"\" Implements cosine of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of cos\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.cos(z.real), -np.sin(z.real) * z.dual)\n",
    "\n",
    "def tan(z):\n",
    "\t\"\"\" Implements tangent of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of tan\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.tan(z.real), (1 / (np.cos(z.real)**2)) * z.dual)\n",
    "\n",
    "def arcsin(z):\n",
    "\t\"\"\" Implements arcsine of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of arcsin\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.arcsin(z.real), (1 / np.sqrt(1 - (z.real**2))) * z.dual)\n",
    "\n",
    "def arccos(z):\n",
    "\t\"\"\" Implements arccosine of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of arccos\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.arccos(z.real), (1 / np.sqrt(1 - (z.real**2))) * z.dual * -1)\n",
    "\n",
    "def arctan(z):\n",
    "\t\"\"\" Implements arctan of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of arctan\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.arctan(z.real), (1 / (1 + (z.real**2))) * z.dual)\n",
    "\n",
    "def sinh(z):\n",
    "\t\"\"\" Implements hyperbolic sine of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of sinh\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.sinh(z.real), np.cosh(z.real) * z.dual)\n",
    "\n",
    "def cosh(z):\n",
    "\t\"\"\" Implements hyperbolic cosine of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of cosh\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.cosh(z.real), np.sinh(z.real) * z.dual)\n",
    "\n",
    "def tanh(z):\n",
    "\t\"\"\" Implements hyperbolic tangent of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of tanh\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(np.tanh(z.real), (1 / np.cosh(z.real))**2 * z.dual)\n",
    "\n",
    "def logistic(z):\n",
    "\t\"\"\" Implements the sigmoid logistic function of a DualNumber\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: DualNumber\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tDualNumber\n",
    "\t\tResult of sigmoid function\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a DualNumber\n",
    "\t\"\"\"\n",
    "\n",
    "\tif not isinstance(z, DualNumber):\n",
    "\t\traise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "\treturn DualNumber(1 / (1 + np.exp(-z.real)),\\\n",
    "\t\t(np.exp(-z.real) / (1 + np.exp(-z.real))**2) * z.dual )\n",
    "```\n",
    "\n",
    "#### rFunctions: functions overloaded for reverse mode\n",
    "These overloaded functions are intended to work with instances of a Graph class (as was previously described)\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "rfunctions module\n",
    "Implements mathematical functions for the best_autodiff package\n",
    "Functions are intended to work with graph instances\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from best_autodiff.graph import Graph\n",
    "\n",
    "__all__ = [\"sqrt\", \"log\", \"root\", \"exp\", \"sin\", \"cos\", \"tan\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"logistic\"]\n",
    "\n",
    "_scalars_types = (int, float, np.int32, np.int64, np.float64)\n",
    "_array_types = (list, np.ndarray)\n",
    "\n",
    "def sqrt(z):\n",
    "    \"\"\" \n",
    "    Implements sqrt function of a Graph instance using any base\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\tbase: int, float, np.int32, np.int64 or np.float64\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "    ValueError\n",
    "        If z < 0\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph([4, 25])\n",
    "    >>> log(z)\n",
    "    Graph([2. 5.])\n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    if (z.value < 0).any():\n",
    "        raise ValueError(f\"Domain out of range\")\n",
    "    else:\n",
    "        value = np.sqrt(z.value)\n",
    "        local_gradients = (\n",
    "            (z, (1/2)*(z.value**(-1/2))),\n",
    "        )\n",
    "        return Graph(value, local_gradients)\n",
    "\n",
    "def log(z, base=np.e):\n",
    "    \"\"\" \n",
    "    Implements log function of a Graph instance using any base\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\tbase: int, float, np.int32, np.int64 or np.float64\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "\t\tIf base is not int, float, np.int32, np.int64 or np.float64\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(23)\n",
    "    >>> log(z)\n",
    "    Graph([3.13549422])\n",
    "    >>> z = Graph([1,23])\n",
    "    >>> log(z, 123)\n",
    "    Graph([0.       0.651574])\n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    if not isinstance(base, _scalars_types):\n",
    "        raise TypeError(f\"Unsupported type {type(base)}\")\n",
    "    value = np.log(z.value) / np.log(base)\n",
    "    local_gradients = (\n",
    "        (z, 1. / (z.value * np.log(base))),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def root(z, n=2):\n",
    "    \"\"\" \n",
    "    Implements function to take the nth root of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\tn: int, float, np.int32, np.int64 or np.float64\n",
    "\t\tnth root of a Graph instance\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "\t\tIf n is not int, float, np.int32, np.int64 or np.float64\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph([1, 2, 3])\n",
    "    >>> root(z) # same as sqrt\n",
    "    Graph([1.         1.41421356 1.73205081])\n",
    "    >>> z = Graph(5)\n",
    "    >>> root(z, 10)\n",
    "    Graph([1.17461894])\n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    if not isinstance(n, _scalars_types):\n",
    "        raise TypeError(f\"Unsupported type {type(n)}\")\n",
    "    if (z.value < 0).any():\n",
    "        raise ValueError(f\"Domain out of range\")\n",
    "    value = z.value ** (1/n)\n",
    "    local_gradients = (\n",
    "        (z, (1/n) * ((z.value)**(1/n - 1))),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def exp(z):\n",
    "    \"\"\" \n",
    "    Implements exp function of a Graph instance using any base\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\tbase: int, float, np.int32, np.int64 or np.float64\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "\t\tIf base is not int, float, np.int32, np.int64 or np.float64\n",
    "    ValueError\n",
    "        If base is negative\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph([2, 3])\n",
    "    >>> exp(z, base=10)\n",
    "    Graph([ 100 1000])\n",
    "\t\"\"\"\n",
    "\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    value = np.power(np.e, z.value)\n",
    "    local_gradients = (\n",
    "        (z, value),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def sin(z):\n",
    "    \"\"\"\n",
    "    Implements sine of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a Graph instance\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(7)\n",
    "    >>> sin(z)\n",
    "    Graph([0.6569866])\n",
    "    >>> z = Graph(7)\n",
    "    >>> sin(z)\n",
    "    Graph([0.84147098 0.90929743 0.14112001])\n",
    "    \"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    value = np.sin(z.value)\n",
    "    local_gradients = (\n",
    "        (z, np.cos(z.value)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def cos(z):\n",
    "    \"\"\" \n",
    "    Implements cos function of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(7)\n",
    "    >>> cos(z)\n",
    "    Graph([0.75390225])\n",
    "    >>> z = Graph(0)\n",
    "    >>> cos(z)\n",
    "    Graph([1.])\n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "    value = np.cos(z.value)\n",
    "    local_gradients = (\n",
    "        (z, -np.sin(z.value)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def tan(z):\n",
    "    \"\"\"\n",
    "    Implements tangent of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a Graph instance\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(7)\n",
    "    >>> tan(z)\n",
    "    Graph([0.87144798])\n",
    "    >>> z = Graph(7)\n",
    "    >>> tan(z)\n",
    "    Graph([ 1.55740772 -2.18503986 -0.14254654])\n",
    "    \"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    for i in z.value:\n",
    "        if (i / (np.pi/2)) % 2 == 1:\n",
    "            raise ValueError('Tangent domain error')\n",
    "    value = np.tan(z.value)\n",
    "    local_gradients = (\n",
    "        (z, 1/np.cos(z.value)**2),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def arcsin(z):\n",
    "    \"\"\" \n",
    "    Implements arcsin function of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "    ValueError\n",
    "        If z.value elements are not between -1 and 1\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(0.9)\n",
    "    >>> arcsin(z)\n",
    "    Graph([1.11976951])\n",
    "    >>> z = Graph(-0.5)\n",
    "    >>> arcsin(z)\n",
    "    Graph([-0.52359878])\n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    if (z.value > 1).all() or (z.value < -1).all():\n",
    "        raise ValueError(f\"math domain error\")\n",
    "\n",
    "    value = np.arcsin(z.value)\n",
    "    local_gradients = (\n",
    "        (z, 1/(np.sqrt(1-z.value**2))),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def arccos(z):\n",
    "    \"\"\" \n",
    "    Implements arccos function of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "    ValueError\n",
    "        If z.value elements are not between -1 and 1\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(0.9)\n",
    "    >>> arccos(z)\n",
    "    Graph([0.45102681])\n",
    "    >>> z = Graph(-0.5)\n",
    "    >>> arccos(z)\n",
    "    Graph([2.0943951])\n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    if (z.value > 1).all() or (z.value < -1).all():\n",
    "        raise ValueError(f\"math domain error\")\n",
    "\n",
    "    value = np.arccos(z.value)\n",
    "    local_gradients = (\n",
    "        (z, -1/(np.sqrt(1-z.value**2))),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def arctan(z):\n",
    "    \"\"\"\n",
    "    Implements arctangent of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a Graph instance\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(7)\n",
    "    >>> arctan(z)\n",
    "    Graph([1.42889927])\n",
    "    >>> z = Graph(7)\n",
    "    >>> arctan(z)\n",
    "    Graph([0.78539816 1.10714872 1.24904577])\n",
    "    \"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    value = np.arctan(z.value)\n",
    "    local_gradients = (\n",
    "        (z, 1/(1 + z.value**2)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def sinh(z):\n",
    "    \"\"\" \n",
    "    Implements sinh function of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(0.9)\n",
    "    >>> sinh(z)\n",
    "    Graph([1.02651673])\n",
    "    >>> z = Graph(-0.5)\n",
    "    >>> sinh(z)\n",
    "    Graph([-0.52109531]) \n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "    value = np.sinh(z.value)\n",
    "    local_gradients = (\n",
    "        (z, np.cosh(z.value)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def cosh(z):\n",
    "    \"\"\"\n",
    "    Implements cosh of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a Graph instance\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(7)\n",
    "    >>> cosh(z)\n",
    "    Graph([548.31703516])\n",
    "    >>> z = Graph([0,1,2])\n",
    "    >>> cosh(z)\n",
    "    Graph([1.         1.54308063 3.76219569])\n",
    "    \"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    value = np.cosh(z.value)\n",
    "    local_gradients = (\n",
    "        (z, np.sinh(z.value)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def tanh(z):\n",
    "    \"\"\" \n",
    "    Implements sinh function of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not Graph\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(0.9)\n",
    "    >>> tanh(z)\n",
    "    Graph([0.71629787])\n",
    "    >>> z = Graph(-0.5)\n",
    "    >>> tanh(z)\n",
    "    Graph([-0.46211716]) \n",
    "\t\"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "\n",
    "    value = np.tanh(z.value)\n",
    "    local_gradients = (\n",
    "        (z, 1/(np.cosh(z.value)**2)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "\n",
    "def logistic(z):\n",
    "    \"\"\"\n",
    "    Implements logistic function of a Graph instance\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tz: Graph\n",
    "\n",
    "\tRaises\n",
    "\t------\n",
    "\tTypeError\n",
    "\t\tIf z is not a Graph instance\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = Graph(10)\n",
    "    >>> logistic(z)\n",
    "    Graph([0.9999546])\n",
    "    >>> z = Graph(-0.1)\n",
    "    >>> logistic(z)\n",
    "    Graph([0.47502081])\n",
    "    \"\"\"\n",
    "    if not isinstance(z, Graph):\n",
    "        raise TypeError(f\"Unsupported type {type(z)}\")\n",
    "    value = 1/(1+np.exp(-z.value))\n",
    "    local_gradients = (\n",
    "        (z, np.exp(-z.value)/((1+np.exp(-z.value))**2)),\n",
    "    )\n",
    "    return Graph(value, local_gradients)\n",
    "```\n",
    "\n",
    "#### Other Libraries\n",
    "Our package also uses NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znmUpWIgYJTV"
   },
   "source": [
    "## Licensing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtOlzXAMbM4O"
   },
   "source": [
    "As one of the most liberal licenses, MIT license allows modification, distribution, copying and selling. Others can change the software however they wish for both commercial and private use. We will use the Numpy library and there is no patent included. For the class project, we would like our work to be permissive with little constraints, so MIT license is a good fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcIygIeBEAd2"
   },
   "source": [
    "# Extension\n",
    "## Reverse Mode\n",
    "### Description\n",
    "Our software has the capability to compute derivatives using the reverse mode for automatic differentiation. In order to accomplish this, we developed 3 additional modules: `reverse.py`, `graph.py` and `rfunctions.py`, as well as their corresponding test modules.\n",
    "\n",
    "`reverse.py` imports the Graph class from `graph.py` to calculate the total derivatives, overloading in  `rfunctions.py` the same functions that were already discussed for forward mode. Unlike forward mode however, our implementation recursively traverses its functions' graph and estimates adjoints for each sub-node, meaning that we store and compute the computational graph by calculating local derivatives at every elementary operation. More specifically, each node and sub-node will have a value and a local_gradients array, containing the local derivatives from parent to child node path.\n",
    " \n",
    "Then, following the chain rule, in order to obtain the total derivative we multiply the edges of each path, and then add these results together, to finally return the Jacobian: a matrix with as many rows as functions are passed, and as many columns as inputs are given, where the element $J_{i,j}$ contains the derivative of the input $j$ with respect to function $i$.\n",
    "\n",
    "Examples and demos can be found in the _How to use_ section of this documentation.\n",
    "\n",
    "### Additional background\n",
    "\n",
    "The reverse mode of automatic differentiation is a two-pass process, as opposed to the m-pass forward mode performs when computing a full gradient. As was already mentioned in the _Background_ section, since reverse mode doesn't evaluate $v_j$ and $D_pv_j$ simulatneously, the nice properties of dual numbers are not longer useful, but because reverse mode doesn't depend on the number of $m$ inputs, it becomes a more efficient way to obtain the Jacobian iff $m >> n$, where n corresponds to the total number of outputs (functions).\n",
    "\n",
    "Reverse mode recovers the partial derivatives of the i-th output $f_i$ with respect to the n variables $v_{j-m}$, with $j=1,2,...n$, by traversing the computational graph backwards. These partial derivatives describe the sensitivity of the output with respect to the intermediate variable $v_{j-m}$:\n",
    "$$\n",
    "\\overline{v}_{j-m} = \\frac{\\partial f_i}{\\partial v_{j-m}}\n",
    "$$\n",
    "\n",
    "$\\overline{v}_{j-m}$ is also known as the adjoint of $v_{j-m}$, and they correspond to the local derivatives metioned in the previous section.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yIYFBs5xdZP"
   },
   "source": [
    "# Broader Impact and Inclusivity Statement\n",
    "## Broader Impact\n",
    "`best_autodiff` calculates derivatives using automatic differentiation (AD), both for forward and reverse modes. Its main advantages are that that it can estimate total derivatives to machine precision with a relatively low computational cost, surpassing other methods such as hand-coded analytical derivatives, as well as numerical and symbolic differentiation. Nevertheless, AD drawbacks should be carefully considered when deciding whether the package would be a good fit for the task at hand. Besides of being very implementation dependant (and thus, prone to development error), AD often acts as a black box. This means that AD will be most relevant if the user is not interested in the derivatives themselves, but is rather looking to use the result for applications in a specific problem or field, particularly science, technology and health. Even if this is the case, we still encourage the users to aim for a basic understanding of AD that will help them further optimize their code and approach the results with a critical eye. As a stand-alone package, we believe that `best_autodiff` does not pose relevant risks to society, nor compromises their users' data privacy.\n",
    "\n",
    "## Inclusivity Statement\n",
    "`best_autodiff` is an open-source project that welcomes collaborations from every developer, without discriminating on any aspect other than the code itself. The team has made great efforts to guarantee that the project is accessible to download and install, and extensively documented and commented the code itself to ease the first approximation to the modules' internals and allow enough flexibility to create custom features. Extensions and improvements are welcomed through Pull Requests (PR) to the project's GitHub Repository. We are committed to give each PR an equal opportunity, thorough review and promptly reply. Particularly in cases where the PR might be rejected, we will provide feedback and communication channels in order to foster an inclusive bidirectional learning environment. Furthermore, we particularly encourage  developers from underrepresented groups in tech and unconventional backgrounds to help improve and extend the `best_autodiff` library, since their point of view is critical to find applications that will make a positive impact in society as a whole, as well as catch blind spots that may be unintentionally amplifying biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbAZy2iINEdN"
   },
   "source": [
    "# Future work and possible extensions\n",
    "\n",
    "### Visualization\n",
    "We would like to provide the users with more comprehensible visualization such a the trace table, including tangent or adjoint depending on the mode, and ploting demos for the gradient trajectory for reverse mode.\n",
    "\n",
    "### Debugging\n",
    "We would like to implement the verbose option for all of our modules, that will allow the user to debug and create custom functionalities more easily.\n",
    "\n",
    "### Runtime Optimization\n",
    "We plan to create runtime tests and possibly identify which parts of the package could be implemented more efficiently. In scenarios such as Neural Network backpropagation, there are millions of calculations to be conducted, so the runtime of this AD package needs to be fast.\n",
    "\n",
    "### More Extensions\n",
    "After perfecting the forward and reverse modes we have now, we can also add more extensions such as optimization, sampling methods, higher-order derivative operations and other domain specific applications depending on what project the AD package is used on. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b5063e4a4d8ab2e7794e758b68514ea039108165a2533eace8866716c79d821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
